{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors: Movie recommendation system\n",
    "\n",
    "## 1. Data loading\n",
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports up-front\n",
    "import pandas as pd\n",
    "\n",
    "movies=pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/k-nearest-neighbors-project-tutorial/main/tmdb_5000_movies.csv\")\n",
    "credits=pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/k-nearest-neighbors-project-tutorial/main/tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets (hint: you don't need SQL here - Pandas can do SQL-like joins directly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1. Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to work with while encoding so that we have the original to go back to if needed\n",
    "encoded_data_df=data_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features contain per-cell JSON formatted data. This is a terrible practice, no competent data scientist would ever produce a dataset this way. Its like building a perfectly tuned, carbon fibre racing bicycle and then using a delicious, bacon, egg and cheese sandwich for the seat. Either one is awesome, but the awkward combination is nonsensical.\n",
    "\n",
    "This kind of thing happens. We can't control the format(s) we find interesting data in. But, as bad*as data scientists, we can use our Python/Pandas chops to extract and parse any data we want it into a useful format. This requires some item-by-item processing and is necessarily messy.\n",
    "\n",
    "In the cell below, I re-wrote the apply() lambda function provided in the 4Geeks solution in a more verbose - but possibly more familiar - style using loops. The lambda apply method is better. Not only is it more succinct, but there is a performance benefit to using apply() vs looping on a Pandas dataframe. I added the loop version for comparison to help you understand what the lambda function is doing:\n",
    "\n",
    "It loads the 'cast' JSON from each row of the dataframe as a dictionary and extracts the value of 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Extract cast names: loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold extracted values\n",
    "extracted_values=[]\n",
    "\n",
    "# Loop on the elements of the cast column\n",
    "for json_string in data_df['cast']:\n",
    "\n",
    "    # Load the json string into a python dictionary\n",
    "    json_list=json.loads(json_string)\n",
    "\n",
    "    # Empty list to hold values from this element\n",
    "    values=[]\n",
    "\n",
    "    # Loop on the first three elements of the json list\n",
    "    for item in json_list[:3]:\n",
    "\n",
    "        # Extract the value for the name key\n",
    "        value=item['name']\n",
    "\n",
    "        # Add it to the list\n",
    "        values.append(value)\n",
    "\n",
    "    extracted_values.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Extract cast names: lambda apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_df['cast']=data_df['cast'].apply(lambda x: [item['name'] for item in json.loads(x)][:3] if pd.notna(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Extract other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the 'keywords' column\n",
    "encoded_data_df['keywords']=data_df['keywords'].apply(lambda x: [item['name'] for item in json.loads(x)][:3] if pd.notna(x) else None)\n",
    "\n",
    "# And the 'genres' column\n",
    "encoded_data_df['genres']=data_df['genres'].apply(lambda x: [item['name'] for item in json.loads(x)][:3] if pd.notna(x) else None)\n",
    "\n",
    "encoded_data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Missing and/or extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for and clean up any junk data, if it exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we need all of the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender function\n",
    "\n",
    "def get_movie_recommendations(movie_title):\n",
    "    '''Takes a movie title string, looks up TFIDF feature vector for that movie\n",
    "    and returns title of top 5 most similar movies.'''\n",
    "\n",
    "    # Your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Target' movie\n",
    "input_movie = \"How to Train Your Dragon\"\n",
    "\n",
    "# Call the recommendation function\n",
    "recommendations = get_movie_recommendations(input_movie)\n",
    "\n",
    "# Print the results\n",
    "print(\"Film recommendations '{}'\".format(input_movie))\n",
    "for movie, distance in recommendations:\n",
    "    print(\"- Film: {}\".format(movie))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
